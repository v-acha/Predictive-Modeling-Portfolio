{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7571a20-ed7c-465c-aa37-a11370d1ec2a",
   "metadata": {},
   "source": [
    "## More Preprocessing\n",
    "Dropping columns that are null, and overwriting clean files in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3c4451-9bae-4767-97f8-e186a456798a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.38.7 requires botocore==1.37.7, but you have botocore 1.37.1 which is incompatible.\n",
      "boto3 1.37.7 requires botocore<1.38.0,>=1.37.7, but you have botocore 1.37.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade \"s3fs>=2023.6.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6bfb11-0f4b-40d6-a264-f1aaf94b71c8",
   "metadata": {},
   "source": [
    "### Load Train, Val, Test in Chunks from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fb48aa-5076-4e6c-9ca0-f33bbae53852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading s3://fireguarddata/data/preprocessed_data/train.csv: 65it [13:02, 12.03s/it]\n",
      "Loading s3://fireguarddata/data/preprocessed_data/val.csv: 9it [01:36, 10.74s/it]\n",
      "Loading s3://fireguarddata/data/preprocessed_data/test.csv: 9it [01:32, 10.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "base_path = \"s3://fireguarddata/data/preprocessed_data/\"\n",
    "paths = {\n",
    "    \"train\": f\"{base_path}train.csv\",\n",
    "    \"val\": f\"{base_path}val.csv\",\n",
    "    \"test\": f\"{base_path}test.csv\"\n",
    "}\n",
    "\n",
    "# Function to load in chunks\n",
    "def load_csv_in_chunks(path, chunksize= 1_000_000):\n",
    "    chunks = []\n",
    "    for chunk in tqdm(pd.read_csv(path, chunksize=chunksize, storage_options={\"anon\": False}), desc=f\"Loading {path}\"):\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Load\n",
    "train_df = load_csv_in_chunks(paths[\"train\"])\n",
    "val_df = load_csv_in_chunks(paths[\"val\"])\n",
    "test_df = load_csv_in_chunks(paths[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817bc99-d9fc-4951-bc3f-2935a72701d0",
   "metadata": {},
   "source": [
    "### Inspecting Current Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5bcdf9-3cd8-41ad-86c2-55439dbdc8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Train:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'number', 'surface', 'depthBelowLandLayer', 'fire_occurrence']\n",
      "\n",
      "Columns in Val:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'number', 'surface', 'depthBelowLandLayer', 'fire_occurrence']\n",
      "\n",
      "Columns in Test:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'number', 'surface', 'depthBelowLandLayer', 'fire_occurrence']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in Train:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nColumns in Val:\")\n",
    "print(val_df.columns.tolist())\n",
    "\n",
    "print(\"\\nColumns in Test:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f460e-4707-431c-8324-f1d3c128a7cb",
   "metadata": {},
   "source": [
    "### Dropping Columns with Nulls Entirely and Overwrite with cleaned Version\n",
    "drop columns with nulls\n",
    "overwrite the current dataset\n",
    "list all columns present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168dda56-44c1-4711-a387-4e3e6572c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values check:\n",
      "Train NaNs: 0\n",
      "Val NaNs: 0\n",
      "Test NaNs: 0\n",
      "\n",
      " Saving cleaned files back to S3...\n",
      "All cleaned files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [\"number\", \"surface\", \"depthBelowLandLayer\"]\n",
    "\n",
    "train_df.drop(columns=cols_to_drop, inplace=True, errors=\"ignore\")\n",
    "val_df.drop(columns=cols_to_drop, inplace=True, errors=\"ignore\")\n",
    "test_df.drop(columns=cols_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Check for any NaNs\n",
    "print(\"Missing values check:\")\n",
    "print(\"Train NaNs:\", train_df.isnull().sum().sum())\n",
    "print(\"Val NaNs:\", val_df.isnull().sum().sum())\n",
    "print(\"Test NaNs:\", test_df.isnull().sum().sum())\n",
    "\n",
    "# Save cleaned versions back to S3\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "print(\"\\n Saving cleaned files back to S3...\")\n",
    "\n",
    "train_df.to_csv(fs.open(paths[\"train\"], \"w\"), index=False)\n",
    "val_df.to_csv(fs.open(paths[\"val\"], \"w\"), index=False)\n",
    "test_df.to_csv(fs.open(paths[\"test\"], \"w\"), index=False)\n",
    "\n",
    "print(\"All cleaned files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b3a905-6bb9-4dc1-bd28-5f1a73ce827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Train:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'fire_occurrence']\n",
      "\n",
      "Columns in Val:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'fire_occurrence']\n",
      "\n",
      "Columns in Test:\n",
      "['latitude', 'longitude', 'u10', 'v10', 'sp', 'lai_hv', 'lai_lv', 'tvl', 'cl', 'swvl1', 'daynight', 'tvh', 'ie', 'd2m', 't2m', 'tcc', 'tcrw', 'rsn', 'sd', 'tsn', 'slt', 'year', 'month', 'day', 'wind_speed', 'wind_direction', 'fuel_load', 'fire_occurrence']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in Train:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nColumns in Val:\")\n",
    "print(val_df.columns.tolist())\n",
    "\n",
    "print(\"\\nColumns in Test:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7694621-a486-47bc-b0e0-ec2844444f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8054293 entries, 0 to 8054292\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   latitude         float64\n",
      " 1   longitude        float64\n",
      " 2   u10              float64\n",
      " 3   v10              float64\n",
      " 4   sp               float64\n",
      " 5   lai_hv           float64\n",
      " 6   lai_lv           float64\n",
      " 7   tvl              float64\n",
      " 8   cl               float64\n",
      " 9   swvl1            float64\n",
      " 10  daynight         float64\n",
      " 11  tvh              float64\n",
      " 12  ie               float64\n",
      " 13  d2m              float64\n",
      " 14  t2m              float64\n",
      " 15  tcc              float64\n",
      " 16  tcrw             float64\n",
      " 17  rsn              float64\n",
      " 18  sd               float64\n",
      " 19  tsn              float64\n",
      " 20  slt              float64\n",
      " 21  year             float64\n",
      " 22  month            float64\n",
      " 23  day              float64\n",
      " 24  wind_speed       float64\n",
      " 25  wind_direction   float64\n",
      " 26  fuel_load        float64\n",
      " 27  fire_occurrence  int64  \n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8969c63-8273-45f5-8280-201d24088c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude           float64\n",
       "longitude          float64\n",
       "u10                float64\n",
       "v10                float64\n",
       "sp                 float64\n",
       "lai_hv             float64\n",
       "lai_lv             float64\n",
       "tvl                float64\n",
       "cl                 float64\n",
       "swvl1              float64\n",
       "daynight           float64\n",
       "tvh                float64\n",
       "ie                 float64\n",
       "d2m                float64\n",
       "t2m                float64\n",
       "tcc                float64\n",
       "tcrw               float64\n",
       "rsn                float64\n",
       "sd                 float64\n",
       "tsn                float64\n",
       "slt                float64\n",
       "year               float64\n",
       "month              float64\n",
       "day                float64\n",
       "wind_speed         float64\n",
       "wind_direction     float64\n",
       "fuel_load          float64\n",
       "fire_occurrence      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8dbb7-aebf-433f-93a1-6b43675d6bff",
   "metadata": {},
   "source": [
    "### Checking memory usage\n",
    "comparing float 64 vs float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e6e365-7f8d-4a08-ad02-f50b3bbf8de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14433292736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "079a4399-5d97-4bdd-a4ee-8ae220644ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb57a1d9-3425-4110-9679-ecf90529e5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7216646432"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168040f7-7df0-4558-80d6-426dc13b6a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64434342, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdff9e-5146-4ec3-8499-d34c838f5ffd",
   "metadata": {},
   "source": [
    "### Updating Fire_occurence threshold to 320 for day and 330 for night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694dc1bc-aca4-4cb2-b978-a4413c8da18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
